---
title: 读 Designing Data-Intensive Application
date: 2019-02-13 16:57:48
tags: 阅读
categories: [设计思想]
---

## 前言
> 拜读大佬的书籍，做个笔记，记录下重点的语句。
---
书本内容：
## 序言
>1. 近几年的软件工程，特别是服务器端和后端系统开发，大量关于数据存储和处理的时髦词汇涌现出来： **NoSQL！大数据！Web-Scale！分片！最终一致性！ACID！ CAP定理！云服务！MapReduce！
实时！**
2. 而**数据密集型应用**（data-intensive applications）正在通过使用这些技术进步来推动可能性的边界。当一个应用被称为**数据密集**型的，如果数据是其主要挑战（数据量，数据复杂度或
数据变化速度）—— 与之相对的是**计算密集型**，即**处理器速度**是其瓶颈。
3. 在技术迅速变化的背后总是存在一些持续成立的原则，无论您使用了特定工具的哪个版本。如果理解了这些原则，就可以领会这些工具的适用场景，如何充分利用它们，以及如何避免其中的陷阱.

## 第一部分：数据系统的基石
1. 第一章将介绍本书使用的术语和方法。可靠性，可扩展性和可维护性 ，这些词汇到底意味着什么？如何实现这些目标？
2. 第二章将对几种不同的数据模型和查询语言进行比较。从程序员的角度看，这是数据库之间最明显的区别。不同的数据模型适用于不同的应用场景。
3. 第三章将深入存储引擎内部，研究数据库如何在磁盘上摆放数据。不同的存储引擎针对不同的负载进行优化，选择合适的存储引擎对系统性能有巨大影响。
4. 第四章将对几种不同的 数据编码进行比较。特别研究了这些格式在应用需求经常变化、模式需要随时间演变的环境中表现如何。

### 第一章：可靠性可，扩展性，可维护性
- 现今很多应用程序都是 **数据密集型（data-intensive）** 的，而非 **计算密集型（compute-intensive）** 的。因此CPU很少成为这类应用的瓶颈，**更大的问题**通常来自数据量、数据
复杂性、以及数据的变更速度。
一旦系统的负载被描述好，就可以研究当负载增加会发生什么。我们可以从两种角度来看：  
- 增加负载参数并保持系统资源（CPU、内存、网络带宽等）不变时，系统性能将受到什么影响？
- 增加负载参数并希望保持性能不变时，需要增加多少系统资源？
这两个问题都需要性能数据，所以让我们简单地看一下如何描述系统性能。
​ 对于Hadoop这样的**批处理系统**，通常关心的是**吞吐量**（throughput），即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间iii。对于在线系统，通常更重要的是服务的
**响应时间**（response time），即客户端发送请求到接收响应之间的时间。

​ 即使不断重复发送同样的请求，每次得到的响应时间也都会略有不同。现实世界的系统会处理各式各样的请求，响应时间可能会有很大差异。因此我们需要将**响应时间**视为一个可以测量的**数值分布**
（distribution），**而不是单个数值**。

### 第二章：数据模型与查询语言
### 第三章：存储与检索
- 我们会研究两大类存储引擎：日志结构（log-structured）的存储引擎，以及面向页面（page-oriented）的存储引擎（例如B树）。
- 冻结段的合并和压缩可以在后台线程中完成，在进行时，我们仍然可以继续使用旧的段文件来正常提供读写请求。合并过程完成后，我们将读取请求转换为使用新的合并段
而不是旧段 —— 然后可以简单地删除旧的段文件。
- **简而言之，一些真正实施中重要的问题是:**
  - 文件格式:
  - 删除记录:
  - 崩溃恢复:
  - 部分写入记录:
  - 并发控制:
- 乍一看，只有追加日志看起来很浪费：为什么不更新文件，用新值覆盖旧值？但是只能追加设计的原因有几个:
  - 追加和分段合并是顺序写入操作，通常比随机写入快得多，尤其是在磁盘旋转硬盘上。
  - 在某种程度上，顺序写入在基于闪存的固态硬盘（SSD）上也是优选的【4】。我们将在
  - 第83页的“比较B-树和LSM-树”中进一步讨论这个问题。
  - 如果段文件是附加的或不可变的，并发和崩溃恢复就简单多了。例如，您不必担心在覆
  - 盖值时发生崩溃的情况，而将包含旧值和新值的一部分的文件保留在一起。
  - 合并旧段可以避免数据文件随着时间的推移而分散的问题。  
- 与往常一样，大量的细节使得存储引擎在实践中表现良好。例如，当查找数据库中不存在的键时，LSM树算法可能会很慢：您必须检查内存表，然后将这些段一直回到最老的（可能必须从磁盘读取每一个），
然后才能确定键不存在。为了优化这种访问，存储引擎通常使用额外的Bloom过滤器【15】
- 布隆过滤器是用于近似集合内容的内存高效数据结构，它可以告诉您数据库中是否出现键，从而为不存在的键节省许多不必要的磁盘读取操作。(没有那就一定是没有，说你有，有百分之95%以上的几率是有的)
-  即使有许多微妙的东西，LSM树的基本思想 —— 保存一系列在后台合并的SSTables —— 简 单而有效。即使数据集比可用内存大得多，它仍能继续正常工作。由于数据按排序顺序存储，
因此可以高效地执行范围查询（扫描所有高于某些最小值和最高值的所有键），并且因 为磁盘写入是连续的，所以LSM树可以支持非常高的写入吞吐量。
- 在B树的一个页面中对子页面的引用的数量称为分支因子。例如，在图3-6中，分支因子是 6 。在实践中，分支因子取决于存储页面参考和范围边界所需的空间量，但通常是几百个。
- 日志结构化的方法在这方面更简单，因为它们在后台进行所 有的合并，而不会干扰传入的查询，并且不时地将旧的分段原子交换为新的分段。
- 这种差异在磁性硬盘驱动器上尤其重要，顺序写入 比随机写入快得多。
- 在许多关系数据库中，事务隔离是通过在键范围上使用锁来实现的，在B树索引中，这些 锁可以直接连接到树
- 在新的数据存储中，**日志结构化索引**变得越来越流行。没有快速和容易的规则来确定哪种类型的存储引擎对你的场景更好，所以值得进行一些经验上的测试.
- 索引中的关键字是查询搜索的内容，但是该值可以是以下两种情况之一：它可以是所讨论的 实际行（文档，顶点），也可以是对存储在别处的行的引用。在后一种情况下，行被存储的 
地方被称为堆文件（heap file），并且存储的数据没有特定的顺序（它可以是仅附加的，或 者可以跟踪被删除的行以便用新数据覆盖它们后来）
- 在聚集索引（在索引中存储所有行数据）和非聚集索引（仅在索引中存储对数据的引用）之间的折衷被称为包含列的索引或覆盖索引，其存储表的一部分在索引内。
这允许通过单独使用索引来回答一些查询（这种情况叫做：索引覆盖（cover）了查询）
- 某些内存中的键值存储（如Memcached）仅用于缓存，在重新启动计算机时丢失的数据是可 以接受的。但其他内存数据库的目标是持久性，可以通过特殊的硬件（例如电池供电的 RAM），
将更改日志写入磁盘，将定时快照写入磁盘或通过复制内存来实现，记忆状态到其他机器。
>诸如VoltDB，MemSQL和Oracle TimesTen等产品是具有关系模型的内存数据库，供应商声
 称，通过消除与管理磁盘上的数据结构相关的所有开销，他们可以提供巨大的性能改进
 【41,42】。 RAM Cloud是一个开源的内存键值存储器，具有持久性（对存储器中的数据以及
 磁盘上的数据使用日志结构化方法）【43】。 Redis和Couchbase通过异步写入磁盘提供了
 较弱的持久性。
 
>磁盘的顺序读速度在100MB/S上下
使用列式存储，分析的时候，可以只扫描需要的那部分数据的时候，减少CPU和磁盘的访问量。同时面向列的存储通常很适合压缩，使用压缩，可以综合CPU和磁盘，发挥最大的效能。
>面向行的存储将每一行保存在一个地方（在堆文件或聚簇索引中）

>在OLTP方面，我们看到了来自两大主流学派的存储引擎：
 日志结构学派
 只允许附加到文件和删除过时的文件，但不会更新已经写入的文件。 Bitcask，SSTables， LSM树，LevelDB，Cassandra，HBase，Lucene等都属于这个组。
 就地更新学派
 将磁盘视为一组可以覆盖的固定大小的页面。 B树是这种哲学的最大的例子，被用在所有主 要的关系数据库中，还有许多非关系数据库。
 第三章：存储与检索
 日志结构的存储引擎是相对较新的发展。他们的主要想法是，他们系统地将随机访问写入顺 序写入磁盘，由于硬盘驱动器和固态硬盘的性能特点，可以实现更高的写入吞吐量。在完成
 OLTP方面，我们通过一些更复杂的索引结构和为保留所有数据而优化的数据库做了一个简短 的介绍。 然后，我们从存储引擎的内部绕开，看看典型数据仓库的高级架构。这一背景说明了为什么
 分析工作负载与OLTP差别很大：当您的查询需要在大量行中顺序扫描时，索引的相关性就会 降低很多。相反，非常紧凑地编码数据变得非常重要，以最大限度地减少查询需要从磁盘读
 取的数据量。我们讨论了列式存储如何帮助实现这一目标。 作为一名应用程序开发人员，如果您掌握了有关存储引擎内部的知识，那么您就能更好地了 解哪种工具最适合您的特定应用程序。
 如果您需要调整数据库的调整参数，这种理解可以让 您设想一个更高或更低的值可能会产生什么效果。 尽管本章不能让你成为一个特定存储引擎的调参专家，但它至少有大概率使你有了足够的概 
 念与词汇储备去读懂数据库的文档，从而选择合适的数据库。

>
### 第四章：编码与演化
> 本章中将介绍几种编码数据的格式，包括 JSON，XML，Protocol Buffers，Thrift和Avro。

- 需要在两种表示之间进行某种类型的翻译。 从内存中表示到字节序列的转换称为编码（Encoding）（也称为序列化（serialization）或编组（marshalling）），反过来称为解码
  （Decoding） （解析（Parsing），反序列化（deserialization），反编组() unmarshalling）） 。
- Java的内置序列化由于其糟糕的性能和臃肿的编码而臭名昭着【8】。  

## 第二部分：分布式数据
### 第五章：复制
### 第六章：分区
### 第七章：事务
### 第八章：分布式系统的麻烦
### 第九章：一致性与共识
## 第三部分：派生数据
### 第十章：批处理
### 第十一章：流处理
### 第十二章：数据系统的未来